{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer SOMA -  2Ô∏è‚É£\n",
    " üöß WIP üöß (üö®üö®üö®üö® Steps 3-9 depend on establishing a good solution here.)\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE: ‚úÖ Infer sub-cellular component SOMA in order to understand interactome \n",
    "\n",
    "To measure shape, position, and size of the cell body -- the soma.    There are a variety of signals from which we could make this inference.  The two most promising are a composite signal including the residual from linear unmixing (e.g. `ch = [1, 4, 5,7]`) and a signal derived from the lysosome channel (`ch = 1`).    In all procdures scaling the intensities to find the lower florescence signals at the edge of the soma against baseline is employed.  \n",
    "\n",
    "In the long term we can build of a database of \"ground truth\" by sourcing additional markers which can be iteratively improved.  For example using the Allen Cell \"Label Free\" segmentation results should provide a good corroboration or constraints to the procedures outlined below.  \n",
    "\n",
    "Three possible _workflows_ are illustrated below.\n",
    "\n",
    "Dependencies:\n",
    "The CYTOSOL inference rely on the NUCLEI AND SOMA inference.  Therefore all of the sub-cellular objects rely on this segmentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of infer_subc.organelles failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/opt/anaconda3/envs/napariNEW/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/Users/ahenrie/Projects/Imaging/infer-subc/infer_subc/organelles/__init__.py\", line 1, in <module>\n",
      "    from .nuclei import infer_NUCLEI\n",
      "  File \"/Users/ahenrie/Projects/Imaging/infer-subc/infer_subc/organelles/nuclei.py\", line 40\n",
      "    def __init__(self, priors: ObjectStats)\n",
      "                                           ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# # function for core algorithm\n",
    "from scipy import ndimage as ndi\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters\n",
    "from skimage import morphology\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc.utils.file_io import read_input_image, list_image_files, export_ome_tiff\n",
    "from infer_subc.utils.img import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from infer_subc.organelles.soma import infer_SOMA1, infer_SOMA2, infer_SOMA3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING  OBJECTIVE :  infer SOMA\n",
    " \n",
    "> #### Note:  we are using the Nuclei of the brightest cell to aid in inferring the Soma and Cytosol objects.   Because we do NOT have a direct cell membrane / soma signal this is the trickiest and potentially problematic part of the overall sub-cellular component inference.   The Soma (via the Cytosol mask) will be used to define ALL subsequent sub-cellular Objects.\n",
    "\n",
    "------------------------\n",
    "# LOAD RAW IMAGE DATA\n",
    "Identify path to _raw_ image data and load our example image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "test_img_name = img_file_list[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bioim_image = read_input_image(test_img_name)\n",
    "img_data = bioim_image.image\n",
    "raw_meta_data = bioim_image.raw_meta\n",
    "ome_types = []\n",
    "meta_dict = bioim_image.meta\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_root_path / \"inferred_objects\" \n",
    "object_name = 'NU_object'\n",
    "\n",
    "NU_bioim = read_input_image( out_path/ f\"{object_name}.ome.tiff\"  )\n",
    "NU_object = NU_bioim.image\n",
    "NU_labels = label(NU_object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #1  - modified MCZ 3/20\n",
    "\n",
    "Segmentation on a 3 channel composite as per 3/20 pipeline from MCZ\n",
    "Summary - Starting with a linear combination of three signals,  the signal is smoothed and non-linearly combined (logrithmic and edge detected) for thresholding. \n",
    "## summary of steps\n",
    "\n",
    "‚û°Ô∏è INPUT\n",
    "- multi-channel sum (4*1,5,7)\n",
    "- labeled NUCLEI (objective #1)\n",
    "\n",
    "PRE-PROCESSING\n",
    "- ne-noise and somoothe\n",
    "- log transform inensities\n",
    "- scale to max 1.0\n",
    "- create non-linear aggregate of log-intensity + scharr filtered \n",
    "\n",
    "CORE PROCESSING\n",
    "- mask object segmentation at bottom\n",
    "\n",
    "POST-PROCESSING\n",
    "  - fill holes\n",
    "  - remove small objects\n",
    "\n",
    "POST-PROCESSING\n",
    "  - keep only the \"most intense\" Soma\n",
    "\n",
    "\n",
    "OUTPUT ‚û°Ô∏è \n",
    "- mask of SOMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median filtering scale is ~ : [0.5804527163320905, 0.3194866073934927, 0.3194866073934927]\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# DEFAULT PARAMETERS:\n",
    "#   note that these parameters are supposed to be fixed for the structure\n",
    "#   and work well accross different datasets\n",
    "# default_params = defaultdict(str)\n",
    "\n",
    "default_params = defaultdict(str, **{\n",
    "    #\"intensity_norm_param\" : [0.5, 15]\n",
    "    \"intensity_norm_param\" : [0],\n",
    "    \"gaussian_smoothing_sigma\" : 1.34,\n",
    "    \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "    \"dot_2d_sigma\" : 2,\n",
    "    \"dot_2d_sigma_extra\" : 1,\n",
    "    \"dot_2d_cutoff\" : 0.025,\n",
    "    \"min_area\" : 10,\n",
    "    \"low_level_min_size\" :  100,\n",
    "    \"median_filter_size\" : 10\n",
    "})\n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "# calculate a filter dimension for median filtering which considers the difference in scale of Z\n",
    "z_factor = scale[0]//scale[1]\n",
    "med_filter_size = 4 #2D \n",
    "med_filter_size_3D = (1,med_filter_size,med_filter_size)  # set the scale for a typical median filter\n",
    "print(f\"median filtering scale is ~ : { [x*y for x,y in zip(scale,med_filter_size_3D)]}\")\n",
    "\n",
    "default_params['z_factor'] = z_factor\n",
    "default_params['scale'] = scale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = (4. * img_data[1,:,:,:].copy() + \n",
    "                               1. * img_data[5,:,:,:].copy() + \n",
    "                               1. * img_data[7,:,:,:].copy() )\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "#intensity_norm_param = [0.5, 15]\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "\n",
    "med_filter_size = 15  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "#\n",
    "\n",
    "# Linear-ish smoothing\n",
    "raw_soma_linear = intensity_normalization( struct_img_raw ,  scaling_param=scaling_param)\n",
    "\n",
    "# structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "struct_img = median_filter_slice_by_slice( \n",
    "                                                                raw_soma_linear,\n",
    "                                                                size=med_filter_size  )\n",
    "\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "\n",
    "# NON-Linear aggregation\n",
    "log_image, d = log_transform( structure_img_smooth ) \n",
    "log_image = intensity_normalization(  log_image,  scaling_param=[0] )\n",
    "\n",
    "edges = filters.scharr(log_image)\n",
    "\n",
    "composite_soma = intensity_normalization(  edges,  scaling_param=[0] ) + log_image \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "    \n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "bw, _bw_low_level = MO(composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "                                                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " remove hole size  ~ : 6.3897321478698546 microns, scale:(0.5804527163320905, 0.07987165184837318, 0.07987165184837318)\n",
      " remove small objects  size  ~ : 3.594224333176793 microns, scale:(0.5804527163320905, 0.07987165184837318, 0.07987165184837318)\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "# 2D \n",
    "width = 80  \n",
    "removed_holes = aicssegmentation.core.utils.hole_filling(bw, hole_min =0. , hole_max=width**2, fill_2d = True) \n",
    "\n",
    "print(f\" remove hole size  ~ : { scale[1]*width} microns, scale:{scale}\")\n",
    "\n",
    "width = 45  \n",
    "cleaned_img = aicssegmentation.core.utils.size_filter(removed_holes, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= width**2, \n",
    "                                                         method = \"slice_by_slice\" ,\n",
    "                                                         connectivity=1)\n",
    "print(f\" remove small objects  size  ~ : { scale[1]*width} microns, scale:{scale}\")\n",
    "\n",
    "# limit the labeling to where we have soma or NUclear signal\n",
    "watershed_mask = np.logical_or(cleaned_img, NU_labels > 0)\n",
    "inverted_img = 1. - composite_soma\n",
    "\n",
    "labels_out = watershed(\n",
    "            connectivity=np.ones((3, 3,3), bool),\n",
    "            image=inverted_img,\n",
    "            markers=NU_labels,\n",
    "            mask=watershed_mask,\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'labels_out' at 0x1475a2430>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "else: \n",
    "    viewer.add_image(\n",
    "        cleaned_img,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_labels(\n",
    "    labels_out,\n",
    "    scale=scale \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST POST-PROCESSING\n",
    "\n",
    "Re-mask the image based on the label which has the highst total intensity SOMA.  Then clean and re-label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST- POST_PROCESSING\n",
    "###################\n",
    "\n",
    "# keep the \"SOMA\" which contains the highest total signal\n",
    "all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "total_signal = [ raw_soma_linear[labels_out == label].sum() for label in all_labels]\n",
    "# combine NU and \"labels\" to make a SOMA\n",
    "keep_label = all_labels[np.argmax(total_signal)]\n",
    "\n",
    "# now use all the NU labels which AREN't keep_label and add to mask and re-label\n",
    "masked_composite_soma = composite_soma.copy()\n",
    "new_NU_mask = np.logical_and( NU_labels !=0 ,NU_labels != keep_label)\n",
    "\n",
    "masked_composite_soma[new_NU_mask] = 0\n",
    "\n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "bw, _bw_low_level = MO(masked_composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "                                                \n",
    "# 2D Cleaning\n",
    "width = 80  \n",
    "removed_holes = aicssegmentation.core.utils.hole_filling(bw, hole_min =0. , hole_max=width**2, fill_2d = True) \n",
    "width = 45  \n",
    "cleaned_img = aicssegmentation.core.utils.size_filter(removed_holes, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= width**2, \n",
    "                                                         method = \"slice_by_slice\" ,\n",
    "                                                         connectivity=1)\n",
    "\n",
    "watershed_mask = np.logical_or(cleaned_img, NU_labels == keep_label)\n",
    "inverted_img = 1. - composite_soma\n",
    "\n",
    "masked_labels_out = watershed(\n",
    "            connectivity=np.ones((3, 3,3), bool),\n",
    "            image=inverted_img,\n",
    "            markers=NU_labels,\n",
    "            mask=watershed_mask,\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'masked_labels_out' at 0x1696580a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer.add_labels(\n",
    "    masked_labels_out,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "# NOTE: for the test img there is an artifact in the upper left... might need to  first exclude regions touching the edge of the image \n",
    "# '/Users/ahenrie/Projects/Imaging/mcz_subcell/data/raw/ZSTACK_PBTOhNGN2hiPSCs_BR3_N04_Unmixed.czi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE `infer_SOMA1` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# 2a.  infer_SOMA1\n",
    "##########################\n",
    "def _infer_SOMA1(struct_img: np.ndarray, NU_labels: np.ndarray,  in_params:dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer SOMA from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the SOMA signal\n",
    "\n",
    "    NU_labels: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of SOMA\n",
    "        label\n",
    "            label (could be more than 1)\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "\n",
    "    #TODO: replace params below with the input params\n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "    # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    # Linear-ish processing\n",
    "    med_filter_size = 15   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice(  struct_img,\n",
    "                                                                            size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "    gaussian_smoothing_sigma = 1.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    # non-Linear processing\n",
    "    log_img, d = log_transform( struct_img ) \n",
    "    log_img = intensity_normalization(  log_img,  scaling_param=[0] )\n",
    "\n",
    "    struct_img = intensity_normalization(  filters.scharr(log_img),  scaling_param=[0] )  + log_img\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    local_adjust = 0.5\n",
    "    low_level_min_size = 100\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    struct_obj, _bw_low_level = MO(struct_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "\n",
    "    out_p[\"local_adjust\"] = local_adjust \n",
    "    out_p[\"low_level_min_size\"] = low_level_min_size \n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "\n",
    "    # 2D \n",
    "    hole_max = 80  \n",
    "    struct_obj = hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "    small_object_max = 35\n",
    "    struct_obj = size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"slice_by_slice\" ,\n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    labels_out = watershed(\n",
    "                connectivity=np.ones((3, 3,3), bool),\n",
    "                image=1. - struct_img,\n",
    "                markers=NU_labels,\n",
    "                mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "                )\n",
    "    ###################\n",
    "    # POST- POST_PROCESSING\n",
    "    ###################\n",
    "    # keep the \"SOMA\" label which contains the highest total signal\n",
    "    all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "    total_signal = [ scaled_signal[labels_out == label].sum() for label in all_labels]\n",
    "    # combine NU and \"labels\" to make a SOMA\n",
    "    keep_label = all_labels[np.argmax(total_signal)]\n",
    "\n",
    "    # now use all the NU labels which AREN't keep_label and add to mask and re-label\n",
    "    masked_composite_soma = struct_img.copy()\n",
    "    new_NU_mask = np.logical_and( NU_labels !=0 ,NU_labels != keep_label)\n",
    "\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    masked_composite_soma[new_NU_mask] = 0\n",
    "    struct_obj, _bw_low_level = MO(masked_composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "\n",
    "    struct_obj = hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    struct_obj = size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"slice_by_slice\" ,\n",
    "                                                            connectivity=1)\n",
    "    masked_labels_out = watershed(\n",
    "                connectivity=np.ones((3, 3,3), bool),\n",
    "                image=1. - struct_img,\n",
    "                markers=NU_labels,\n",
    "                mask= np.logical_or(struct_obj, NU_labels == keep_label),\n",
    "                )\n",
    "                \n",
    "\n",
    "    retval = (struct_obj,  masked_labels_out, out_p)\n",
    "    return retval\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    ">> NOTE:  this strategy to create aggregate signals by non-linearly filtering multiple floursecence signals and then re-labeling/segmenting (POST POST-PROCESSING) doesn't seem to be robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  set up files\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_root_path / \"inferred_objects\" \n",
    "object_name = 'NU_object'\n",
    "\n",
    " \n",
    "default_params = defaultdict(str, **{\n",
    "    #\"intensity_norm_param\" : [0.5, 15]\n",
    "    \"intensity_norm_param\" : [0],\n",
    "    \"gaussian_smoothing_sigma\" : 1.34,\n",
    "    \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "    \"dot_2d_sigma\" : 2,\n",
    "    \"dot_2d_sigma_extra\" : 1,\n",
    "    \"dot_2d_cutoff\" : 0.025,\n",
    "    \"min_area\" : 10,\n",
    "    \"low_level_min_size\" :  100,\n",
    "    \"median_filter_size\" : 10\n",
    "})\n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "# calculate a filter dimension for median filtering which considers the difference in scale of Z\n",
    "z_factor = scale[0]//scale[1]\n",
    "med_filter_size = 4 #2D \n",
    "med_filter_size_3D = (1,med_filter_size,med_filter_size)  # set the scale for a typical median filter\n",
    "print(f\"median filtering scale is ~ : { [x*y for x,y in zip(scale,med_filter_size_3D)]}\")\n",
    "\n",
    "default_params['z_factor'] = z_factor\n",
    "default_params['scale'] = scale\n",
    "# DEFAULT PARAMETERS:\n",
    "#intensity_norm_param = [0.5, 15]\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "\n",
    "\n",
    "i = 4\n",
    "target_file = img_file_list[i]\n",
    "\n",
    "\n",
    "bioim_image = read_input_image(target_file)\n",
    "img_data = bioim_image.image\n",
    "raw_meta_data = bioim_image.raw_meta\n",
    "ome_types = []\n",
    "meta_dict = bioim_image.meta\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n",
    "\n",
    "#-------------------\n",
    "\n",
    "\n",
    "raw_nuclei = img_data[0,:,:,:].copy()\n",
    "NU_object, NU_label, out_p =  infer_NUCLEI(raw_nuclei.copy(), default_params) \n",
    "\n",
    "\n",
    "###################\n",
    "# SOMA INPUT\n",
    "###################\n",
    "raw_soma = (4. * img_data[1,:,:,:].copy() + \n",
    "                            1. * img_data[5,:,:,:].copy() + \n",
    "                            1. * img_data[7,:,:,:].copy() )\n",
    "\n",
    "struct_img = intensity_normalization( raw_soma.copy() ,  scaling_param=scaling_param)\n",
    "SO_object, SO_label, out_p =  _infer_SOMA1(struct_img.copy(), NU_label, out_p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(\n",
    "    raw_nuclei,\n",
    "    scale=scale,\n",
    "    blending='additive'\n",
    ")\n",
    "viewer.scale_bar.visible = True\n",
    "\n",
    "viewer.add_image(\n",
    "    NU_object,\n",
    "    scale=scale,\n",
    "    colormap='blue', \n",
    "    blending='additive'\n",
    ")\n",
    "\n",
    "viewer.dims.ndisplay = 3\n",
    "viewer.camera.angles = (-30, 25, 120)\n",
    "\n",
    "viewer.add_image(\n",
    "    raw_soma,\n",
    "    scale=scale,\n",
    "    blending='additive'\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    SO_object,\n",
    "    scale=scale,\n",
    "    blending='additive'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "# WORKFLOW #2\n",
    "\n",
    "Segmentation on a 4 channel composite as per 6/22 CellProfiler pipeline from MCZ\n",
    "## summary of steps\n",
    "\n",
    "‚û°Ô∏è INPUT\n",
    "- channel  1,4,5, and 7\n",
    "- labeled NUCLEI (objective #1)\n",
    "\n",
    "PRE-PROCESSING\n",
    "-  scale to max 1.0\n",
    "- gaussian  Filter window 10\n",
    "\n",
    "CORE-PROCESSING\n",
    "  - watershed from NU, global threshold, minimum cross-entropy\n",
    "  - threshold smoothing scale: 1 pixel\n",
    "  - threshold correction factor: .5 (more lenient)\n",
    "  - lower / upper bounds  (0,1)\n",
    "  - log transformed thresholding\n",
    "  - fill holes\n",
    "    - discard objects on borde\n",
    "    - fill holes\n",
    "\n",
    "POST-PROCESSING\n",
    "  - fill holes\n",
    "  - remove small objects\n",
    "\n",
    "POST-PROCESSING\n",
    "  - keep only the \"most intense\" Soma\n",
    "\n",
    "\n",
    "OUTPUT ‚û°Ô∏è \n",
    "\n",
    "- mask of SOMA\n",
    "- mask of NU (contained by SOMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚û°Ô∏è INPUT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean intensity of the stack: 641.5999045901829\n",
      "the standard deviation of intensity of the stack: 2144.942904845627\n",
      "0.9999 percentile of the stack intensity is: 49648.38039997965\n",
      "minimum intensity of the stack: 0\n",
      "maximum intensity of the stack: 65535\n",
      "suggested upper range is 23.0, which is 49975.2867160396\n",
      "suggested lower range is 0.0, which is 641.5999045901829\n",
      "So, suggested parameter for normalization is [0.0, 23.0]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "\n",
    "composite_channels = [1,4,5,7]\n",
    "\n",
    "gaussian_smoothing_sigma = 8\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "gaussian_smoothing_sigma_3D = [gaussian_smoothing_sigma*scale[2]/x  for x in scale]\n",
    "\n",
    "aicssegmentation.core.pre_processing_utils.suggest_normalization_param(img_data[1,:,:,:]) #  [0.0, 8]\n",
    "#truncate_intensity = raw_soma.mean()+raw_soma.std()*3\n",
    "raw_soma_linear = intensity_normalization(  img_data[composite_channels,:,:,:].copy(), scaling_param=[0] ).sum(axis=0)\n",
    "raw_soma_linear = intensity_normalization(  raw_soma_linear, scaling_param=[0] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "struct_img = raw_soma_linear.copy()\n",
    "\n",
    "# 2D smoothing with gaussian filter\n",
    "gaussian_smoothing_sigma = 3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "med_filter_size = 9\n",
    "#structure_img_median = ndi.median_filter(struct_img,    size=med_filter_size  ) #3D\n",
    "structure_img_median = median_filter_slice_by_slice( \n",
    "                                                                struct_img,\n",
    "                                                                size=med_filter_size )\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(   structure_img_median,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean intensity of the stack: 0.022594163479725156\n",
      "the standard deviation of intensity of the stack: 0.035176025031434015\n",
      "0.9999 percentile of the stack intensity is: 0.562098829807297\n",
      "minimum intensity of the stack: 6.00946325238002e-09\n",
      "maximum intensity of the stack: 1.0\n",
      "suggested upper range is 15.5, which is 0.5678225514669525\n",
      "suggested lower range is 0.5, which is 0.0050061509640081485\n",
      "So, suggested parameter for normalization is [0.5, 15.5]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n",
      "mean intensity of the stack: 0.02121846708738522\n",
      "the standard deviation of intensity of the stack: 0.03109671695313\n",
      "0.9999 percentile of the stack intensity is: 0.49197553144795597\n",
      "minimum intensity of the stack: 0.005571961371672658\n",
      "maximum intensity of the stack: 0.7053786193844717\n",
      "suggested upper range is 15.5, which is 0.5032175798609002\n",
      "suggested lower range is 0.5, which is 0.005670108610820219\n",
      "So, suggested parameter for normalization is [0.5, 15.5]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n",
      "mean intensity of the stack: 0.021218103928360828\n",
      "the standard deviation of intensity of the stack: 0.03191390281334251\n",
      "0.9999 percentile of the stack intensity is: 0.5208109846958499\n",
      "minimum intensity of the stack: 0.005015915674606106\n",
      "maximum intensity of the stack: 0.7679201869925036\n",
      "suggested upper range is 16.0, which is 0.5318405489418411\n",
      "suggested lower range is 0.5, which is 0.005261152521689572\n",
      "So, suggested parameter for normalization is [0.5, 16.0]\n",
      "To further enhance the contrast: You may increase the first value (may loss some dim parts), or decrease the second value(may loss some texture in super bright regions)\n",
      "To slightly reduce the contrast: You may decrease the first value, or increase the second value\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ###############################\n",
    "# PARAMETERS:\n",
    "###########################################\n",
    "# #intensity_norm_param = [0.5, 15]\n",
    "intensity_norm_param = [0]\n",
    "gaussian_smoothing_sigma = 5\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "#structure_img_smooth = raw_gaussian_filter2D\n",
    "# this is closer to the original \n",
    "\n",
    "########################\n",
    "#  CORE PROCESSING\n",
    "######################\n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "\n",
    "bw, _bw_low_level = MO(structure_img_smooth, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.25, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "                                                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "# Clean in 3D\n",
    "\n",
    "width = 5  \n",
    "# discount z direction\n",
    "#segmented_soma = remove_small_objects(bw, min_size=width*width*1.5, connectivity=1, in_place=False)\n",
    "removed_holes = morphology.remove_small_holes(bw, width ** 3 )\n",
    "\n",
    "width = 6  \n",
    "cleaned_img = aicssegmentation.core.utils.size_filter(removed_holes, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= width**3, \n",
    "                                                         method = \"3D\", #\"slice_by_slice\" \n",
    "                                                         connectivity=1)\n",
    "\n",
    "labels_out = watershed(\n",
    "        image=np.abs(ndi.sobel(structure_img_smooth)),\n",
    "        markers=NU_labels,\n",
    "        connectivity=np.ones((3, 3, 3), bool),\n",
    "        mask= np.logical_or(cleaned_img, NU_labels > 0),#cleaned_img,#\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize with `napari`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'labels_out [1]' at 0x16c64d190>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "viewer.add_image(\n",
    "    structure_img_smooth,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    cleaned_img,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.scale_bar.visible = True\n",
    "\n",
    "viewer.add_labels(\n",
    "    labels_out,\n",
    "    scale=scale \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST POST_PROCESSING\n",
    "###################\n",
    "\n",
    "# keep the \"SOMA\" which contains the highest total signal\n",
    "all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "total_signal = [ raw_soma_linear[labels_out == label].sum() for label in all_labels]\n",
    "# combine NU and \"labels\" to make a SOMA\n",
    "keep_label = all_labels[np.argmax(total_signal)]\n",
    "keep_label, total_signal\n",
    "\n",
    "# now use all the NU labels which AREN't keep_label and add to mask and re-label\n",
    "masked_composite_soma = structure_img_smooth.copy()\n",
    "new_NU_mask = np.logical_and( NU_labels !=0 ,NU_labels != keep_label)\n",
    "\n",
    "masked_composite_soma[new_NU_mask] = 0\n",
    "\n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "bw, _bw_low_level = MO(masked_composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.25, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "                                                \n",
    "\n",
    "# clean in 3D\n",
    "width = 5  \n",
    "removed_holes = morphology.remove_small_holes(bw, width ** 3 )\n",
    "\n",
    "width = 6  \n",
    "cleaned_img = aicssegmentation.core.utils.size_filter(removed_holes, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= width**3, \n",
    "                                                         method = \"3D\", #\"slice_by_slice\" \n",
    "                                                         connectivity=1)\n",
    "\n",
    "labels_out = watershed(\n",
    "        image=np.abs(ndi.sobel(structure_img_smooth)),\n",
    "        markers=NU_labels,\n",
    "        connectivity=np.ones((3, 3, 3), bool),\n",
    "        mask=cleaned_img,\n",
    "    )\n",
    "\n",
    "watershed_mask = np.logical_or(cleaned_img, NU_labels == keep_label)\n",
    "masked_labels_out = watershed(\n",
    "            connectivity=np.ones((3, 3,3), bool),\n",
    "            image=np.abs(ndi.sobel(structure_img_smooth)),\n",
    "            markers=NU_labels,\n",
    "            mask=watershed_mask,\n",
    "            )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'masked_labels_out [1]' at 0x16c74fe20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer.add_labels(\n",
    "    masked_labels_out,\n",
    "    scale=scale \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE `infer_SOMA2` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##########################\n",
    "# 2b.  infer_SOMA2\n",
    "########################### copy this to base.py for easy import\n",
    "def _infer_SOMA2(struct_img: np.ndarray, NU_labels: np.ndarray,  in_params:dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer SOMA from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the SOMA signal\n",
    "\n",
    "    NU_labels: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of SOMA\n",
    "        label\n",
    "            label (could be more than 1)\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    #TODO: replace params below with the input params\n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "\n",
    "    # 2D smoothing\n",
    "    # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    med_filter_size = 9   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice( \n",
    "                                                                    struct_img,\n",
    "                                                                    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 3.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    #    edges = filters.scharr(struct_img)\n",
    "    # struct_img, d = log_transform( struct_img ) \n",
    "    # struct_img = intensity_normalization(  struct_img,  scaling_param=[0] )\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    local_adjust = 0.25\n",
    "    low_level_min_size = 100\n",
    "    struct_obj, _bw_low_level = MO(struct_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "    out_p[\"local_adjust\"] = local_adjust \n",
    "    out_p[\"low_level_min_size\"] = low_level_min_size \n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    # 3D cleaning\n",
    "\n",
    "    hole_max = 80  \n",
    "    # discount z direction\n",
    "    struct_obj = hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "    small_object_max = 35\n",
    "    struct_obj = size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"3D\", #\"slice_by_slice\" \n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    labels_out = watershed(\n",
    "                                                image=np.abs(ndi.sobel(struct_img)),\n",
    "                                                markers=NU_labels,\n",
    "                                                connectivity=np.ones((3, 3, 3), bool),\n",
    "                                                mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "                                                )\n",
    "\n",
    "    ###################\n",
    "    # POST- POST_PROCESSING\n",
    "    ###################\n",
    "    # keep the \"SOMA\" label which contains the highest total signal\n",
    "    all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "    total_signal = [ scaled_signal[labels_out == label].sum() for label in all_labels]\n",
    "    # combine NU and \"labels\" to make a SOMA\n",
    "    keep_label = all_labels[np.argmax(total_signal)]\n",
    "\n",
    "    # now use all the NU labels which AREN't keep_label and add to mask and re-label\n",
    "    masked_composite_soma = struct_img.copy()\n",
    "    new_NU_mask = np.logical_and( NU_labels !=0 ,NU_labels != keep_label)\n",
    "\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    masked_composite_soma[new_NU_mask] = 0\n",
    "    struct_obj, _bw_low_level = MO(masked_composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "    # 3D cleaning\n",
    "    struct_obj = hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    struct_obj = size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"3D\", #\"slice_by_slice\" \n",
    "                                                            connectivity=1)\n",
    "    masked_labels_out = watershed(\n",
    "                connectivity=np.ones((3, 3,3), bool),\n",
    "                image=np.abs(ndi.sobel(struct_img)),\n",
    "                markers=NU_labels,\n",
    "                mask= np.logical_or(struct_obj, NU_labels == keep_label),\n",
    "                )\n",
    "                \n",
    "\n",
    "    retval = (struct_obj,  masked_labels_out, out_p)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "\n",
    "# WORKFLOW #3\n",
    "\n",
    "Segmentation on the log-scaled Lysosome signal and aggressively filling holes.\n",
    "## summary of steps\n",
    "\n",
    "INPUT\n",
    "- channel  1 LYSOSOMES\n",
    "- labeled NUCLEI (objective #1)\n",
    "\n",
    "PRE-PROCESSING\n",
    "- ne-noise and somoothe\n",
    "- log transform inensities\n",
    "- scale to max 1.0\n",
    "- create non-linear aggregate of log-intensity + scharr filtered \n",
    "\n",
    "CORE PROCESSING\n",
    "- mask object segmentation at bottom\n",
    "\n",
    "POST-PROCESSING\n",
    "  - fill holes\n",
    "  - remove small objects\n",
    "\n",
    "POST-PROCESSING\n",
    "  - keep only the \"most intense\" Soma\n",
    "\n",
    "\n",
    "OUTPUT\n",
    "- mask of SOMA\n",
    "\n",
    "\n",
    "## INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "\n",
    "composite_channels = [1]\n",
    "struct_img_raw = intensity_normalization(  img_data[1,:,:,:].copy(), scaling_param=[0] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####################\n",
    "# PRE=PROCESSING\n",
    "#####################\n",
    "# 2D linearish\n",
    "struct_img_smooth = struct_img_raw\n",
    "med_filter_size = 3   \n",
    "# structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "struct_img_smooth2 = median_filter_slice_by_slice( \n",
    "                                                                struct_img_smooth,\n",
    "                                                                size=med_filter_size  )\n",
    "\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "struct_img_smooth3 = image_smoothing_gaussian_slice_by_slice(   struct_img_smooth2,\n",
    "                                                                                                    sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                    truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                )\n",
    "\n",
    "# non-linear scaling (log)\n",
    "log_image, d = log_transform( struct_img_smooth3 ) \n",
    "composite_img = intensity_normalization( log_image + filters.scharr(log_image),  scaling_param=[0] )  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "local_adjust = 0.5\n",
    "struct_obj, _bw_low_level = MO(composite_img, \n",
    "                                            global_thresh_method='ave', \n",
    "                                            object_minArea=low_level_min_size, \n",
    "                                            extra_criteria=True,\n",
    "                                            local_adjust= local_adjust, \n",
    "                                            return_object=True,\n",
    "                                            dilate=True)\n",
    "\n",
    "\n",
    "# # this is not actually applied for this workflow,,,,\n",
    "# threshold_correction_factor = 0.9\n",
    "# thresh_min, thresh_max = 0.0000267,.2\n",
    "\n",
    "# threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "# out_p['threshold_factor'] = threshold_factor\n",
    "# out_p['thresh_min'] = thresh_min\n",
    "# out_p['thresh_max'] = thresh_max\n",
    "\n",
    "\n",
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "# 3D cleanibng\n",
    "hole_max = 100  \n",
    "# discount z direction\n",
    "struct_obj = aicssegmentation.core.utils.hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "\n",
    "small_object_max = 30\n",
    "struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                        min_size= small_object_max**3, \n",
    "                                                        method = \"slice_by_slice\" ,\n",
    "                                                        connectivity=1)\n",
    "\n",
    "\n",
    "#  TEST: label without the edges in the composite\n",
    "# labels_out1b = watershed(\n",
    "#             connectivity=np.ones((3, 3,3), bool),\n",
    "#             image=np.abs(filters.sobel(log_image)),\n",
    "#             markers=NU_labels,\n",
    "#             mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "#             )\n",
    "\n",
    "labels_out = watershed(\n",
    "            connectivity=np.ones((3, 3,3), bool),\n",
    "            image=np.abs(filters.sobel(composite_img)),\n",
    "            markers=NU_labels,\n",
    "            mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "            )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize with `napari`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'labels_out [1]' at 0x16cafd730>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "viewer.add_image(\n",
    "    composite_img,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    struct_obj,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.scale_bar.visible = True\n",
    "\n",
    "viewer.add_labels(\n",
    "    labels_out,\n",
    "    scale=scale \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " [2619.450797330675,\n",
       "  2859.1222553264897,\n",
       "  2610.5356374915605,\n",
       "  990.0794537419587,\n",
       "  57165.53406597422,\n",
       "  3592.53461512864,\n",
       "  7857.904203931077,\n",
       "  66.31651789238128,\n",
       "  3.7428702220861])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# POST POST PROCESSING\n",
    "###################\n",
    "\n",
    "# keep the \"SOMA\" which contains the highest total signal\n",
    "all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "total_signal = [ struct_img_raw[labels_out == label].sum() for label in all_labels]\n",
    "# combine NU and \"labels\" to make a SOMA\n",
    "keep_label = all_labels[np.argmax(total_signal)]\n",
    "keep_label, total_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now use all the NU labels which AREN't keep_label and add to mask and re-label\n",
    "# \n",
    "# \n",
    "masked_composite_soma = composite_img.copy()\n",
    "new_NU_mask = np.logical_and( NU_labels !=0 ,NU_labels != keep_label)\n",
    "\n",
    "masked_composite_soma[new_NU_mask] = 0\n",
    "\n",
    "masked_markers = NU_labels.copy()\n",
    "masked_markers[new_NU_mask] = 0\n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "bw, _bw_low_level = MO(masked_composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=False)\n",
    "                                                \n",
    "hole_max = 80  \n",
    "# discount z direction\n",
    "struct_obj = aicssegmentation.core.utils.hole_filling(bw, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "\n",
    "small_object_max = 30\n",
    "struct_obj = aicssegmentation.core.utils.size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                        min_size= small_object_max**3, \n",
    "                                                        method = \"slice_by_slice\" ,\n",
    "                                                        connectivity=1)\n",
    "\n",
    "masked_labels_out = watershed(\n",
    "            connectivity=np.ones((3, 3,3), bool),\n",
    "            image=np.abs(filters.sobel(composite_img)),\n",
    "            markers=masked_markers,\n",
    "            mask= np.logical_or(struct_obj, NU_labels == keep_label),\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "## Doesn't really work... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'bw [3]' at 0x17311dfa0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer.add_labels(\n",
    "    masked_labels_out,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "\n",
    "viewer.add_labels(\n",
    "    masked_markers,\n",
    "    scale=scale \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE `infer_SOMA3` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##########################\n",
    "# 2c.  infer_SOMA3\n",
    "##########################\n",
    "def _infer_SOMA3(struct_img, NU_labels,  in_params) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer SOMA from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the SOMA signal\n",
    "\n",
    "    NU_labels: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of SOMA\n",
    "        label\n",
    "            label (could be more than 1)\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "   # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    med_filter_size = 3   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice( \n",
    "                                                                    struct_img,\n",
    "                                                                    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 1.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    log_img, d = log_transform( struct_img ) \n",
    "    struct_img = intensity_normalization(  log_img + filters.scharr(log_img) ,  scaling_param=[0] )  \n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    local_adjust = 0.5\n",
    "    low_level_min_size = 100\n",
    "    struct_obj, _bw_low_level = MO(struct_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "    out_p[\"local_adjust\"] = local_adjust \n",
    "    out_p[\"low_level_min_size\"] = low_level_min_size \n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    # 2D cleaning\n",
    "    hole_max = 100  \n",
    "    # discount z direction\n",
    "    struct_obj = hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    out_p['hole_max'] = hole_max\n",
    "\n",
    "    small_object_max = 30\n",
    "    struct_obj = size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"slice_by_slice\" ,\n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    labels_out = watershed(\n",
    "                                                image=np.abs(ndi.sobel(struct_img)),  #either log_img or struct_img seem to work, but more spurious labeling to fix in post-post for struct_img\n",
    "                                                markers=NU_labels,\n",
    "                                                connectivity=np.ones((3, 3, 3), bool),\n",
    "                                                mask= np.logical_or(struct_obj, NU_labels > 0),\n",
    "                                                )\n",
    "\n",
    "    ###################\n",
    "    # POST- POST_PROCESSING\n",
    "    ###################\n",
    "    # keep the \"SOMA\" label which contains the highest total signal\n",
    "    all_labels = np.unique(labels_out)[1:]\n",
    "\n",
    "    total_signal = [ scaled_signal[labels_out == label].sum() for label in all_labels]\n",
    "    # combine NU and \"labels\" to make a SOMA\n",
    "    keep_label = all_labels[np.argmax(total_signal)]\n",
    "\n",
    "    # now use all the NU labels which AREN't keep_label and add to mask and re-label\n",
    "    masked_composite_soma = struct_img.copy()\n",
    "    new_NU_mask = np.logical_and( NU_labels !=0 ,NU_labels != keep_label)\n",
    "\n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    masked_composite_soma[new_NU_mask] = 0\n",
    "    struct_obj, _bw_low_level = MO(masked_composite_soma, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "\n",
    "    # 2D cleaning\n",
    "    struct_obj = hole_filling(struct_obj, hole_min =0. , hole_max=hole_max**2, fill_2d = True) \n",
    "    struct_obj = size_filter(struct_obj, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**3, \n",
    "                                                            method = \"slice_by_slice\" ,\n",
    "                                                            connectivity=1)\n",
    "    masked_labels_out = watershed(\n",
    "                connectivity=np.ones((3, 3,3), bool),\n",
    "                image=np.abs(ndi.sobel(struct_img)),  #either log_img or struct_img seem to work, but more spurious labeling to fix in post-post for struct_img\n",
    "                markers=NU_labels,\n",
    "                mask= np.logical_or(struct_obj, NU_labels == keep_label),\n",
    "                )\n",
    "                \n",
    "    retval = (struct_obj,  masked_labels_out, out_p)\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if viewer is None:\n",
    "    viewer = napari.view_image(\n",
    "        composite_soma,\n",
    "        scale=scale,\n",
    "        blending='additive',\n",
    "        colormap='magenta',\n",
    "    )\n",
    "\n",
    "else:\n",
    "    viewer.add_image(\n",
    "        composite_soma,\n",
    "        scale=scale \n",
    "    )\n",
    "\n",
    "viewer.add_image(\n",
    "    log_image,\n",
    "    scale=scale \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "# TEST `infer_SOMA{1,2,3}` exported functions\n",
    "\n",
    "\n",
    "##\n",
    "`infer_SOMA1` procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ahenrie/Projects/Imaging/mcz_subcell/data/raw/ZSTACK_PBTOhNGN2hiPSCs_BR3_N04_Unmixed.czi\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "##  set up files\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "test_img_name = img_file_list[5]\n",
    "\n",
    "bioim_image = read_input_image(test_img_name)\n",
    "img_data = bioim_image.image\n",
    "raw_meta_data = bioim_image.raw_meta\n",
    "ome_types = []\n",
    "meta_dict = bioim_image.meta\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n",
    "\n",
    "#-------------------\n",
    "\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_root_path / \"inferred_objects\" \n",
    "object_name = 'NU_object'\n",
    "\n",
    "#NU_object_filen = export_ome_tiff(NU_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n",
    "\n",
    "NU_bioim = read_input_image( out_path/ f\"{object_name}.ome.tiff\"  )\n",
    "NU_object = NU_bioim.image\n",
    "NU_labels = label(NU_object)\n",
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "struct_img_raw = (4. * img_data[1,:,:,:].copy() + \n",
    "                               1. * img_data[5,:,:,:].copy() + \n",
    "                               1. * img_data[7,:,:,:].copy() )\n",
    "\n",
    "# DEFAULT PARAMETERS:\n",
    "#intensity_norm_param = [0.5, 15]\n",
    "scaling_param = [0]\n",
    "gaussian_smoothing_sigma = 1.\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "dot_2d_sigma = 2\n",
    "dot_2d_sigma_extra = 1\n",
    "dot_2d_cutoff = 0.025\n",
    "min_area = 10\n",
    "low_level_min_size =  100\n",
    "\n",
    "default_params = defaultdict(str, **{\n",
    "    #\"intensity_norm_param\" : [0.5, 15]\n",
    "    \"intensity_norm_param\" : [0],\n",
    "    \"gaussian_smoothing_sigma\" : 1.34,\n",
    "    \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "    \"dot_2d_sigma\" : 2,\n",
    "    \"dot_2d_sigma_extra\" : 1,\n",
    "    \"dot_2d_cutoff\" : 0.025,\n",
    "    \"min_area\" : 10,\n",
    "    \"low_level_min_size\" :  100,\n",
    "    \"median_filter_size\" : 10\n",
    "})\n",
    "\n",
    "struct_img = intensity_normalization( struct_img_raw ,  scaling_param=scaling_param)\n",
    "\n",
    "\n",
    "SO_object, SO_label, out_p =  infer_SOMA1(struct_img.copy(), NU_labels, default_params) \n",
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n",
    "\n",
    "viewer2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SO_object']\n",
      "['SO_label']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "# save results to a tiff file...\n",
    "#  might just want to save as NUMPY arrays for now... \n",
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'SO_object'\n",
    "label_name = 'SO_label'\n",
    "\n",
    "SO_object_filen = export_ome_tiff(SO_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n",
    "SO_object_filen = export_ome_tiff(SO_label, meta_dict, label_name, str(out_path)+\"/\", curr_chan=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'SO_label' at 0x171eb1130>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if viewer2 is None:\n",
    "    viewer2 = napari.view_image(\n",
    "        SO_object,\n",
    "        scale=scale\n",
    "    )\n",
    "else: \n",
    "    viewer2.add_image(\n",
    "        SO_object,\n",
    "        scale=scale\n",
    "    )\n",
    "\n",
    "\n",
    "viewer2.add_labels(\n",
    "    SO_label,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## `infer_SOMA2` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "['SO_object2']\n",
      "['SO_label2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_root_path / \"inferred_objects\" \n",
    "object_name = 'NU_object'\n",
    "\n",
    "#NU_object_filen = export_ome_tiff(NU_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n",
    "\n",
    "NU_bioim = read_input_image( out_path/ f\"{object_name}.ome.tiff\"  )\n",
    "NU_object = NU_bioim.image\n",
    "\n",
    "NU_labels = label(NU_object)\n",
    "\n",
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "\n",
    "composite_channels = [1,4,5,7]\n",
    "raw_soma_linear = intensity_normalization(  img_data[composite_channels,:,:,:].copy(), scaling_param=[0] ).sum(axis=0)\n",
    "#struct_img = intensity_normalization(  raw_soma_linear, scaling_param=[0] )\n",
    "\n",
    "\n",
    "SO_object, SO_label, out_p =  infer_SOMA2(raw_soma_linear.copy(), NU_labels, default_params) \n",
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n",
    "# possibly need to do some post-post-processing to make suer that there is only a single SO_Object?\n",
    "\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'SO_object2'\n",
    "\n",
    "SO_object_filen = export_ome_tiff(SO_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n",
    "\n",
    "# test: does this export work?\n",
    "object_name = 'SO_label2'\n",
    "SO_label_filen = export_ome_tiff(SO_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'SO_label [1]' at 0x173a65fa0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer2.add_image(\n",
    "    raw_soma_linear,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "viewer2.add_image(\n",
    "    SO_object,\n",
    "    scale=scale\n",
    ")\n",
    "viewer2.scale_bar.visible = True\n",
    "\n",
    "viewer2.add_labels(\n",
    "    SO_label,\n",
    "    scale=scale \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## `infer_SOMA3` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "['SO_object3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SO_label3']\n"
     ]
    }
   ],
   "source": [
    "chan_name = 'nuclei'\n",
    "out_path = data_root_path / \"inferred_objects\" \n",
    "object_name = 'NU_object'\n",
    "\n",
    "#NU_object_filen = export_ome_tiff(NU_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n",
    "\n",
    "NU_bioim = read_input_image( out_path/ f\"{object_name}.ome.tiff\"  )\n",
    "NU_object = NU_bioim.image\n",
    "\n",
    "NU_labels = label(NU_object)\n",
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "composite_channels = [1]\n",
    "raw_soma_linear = intensity_normalization(  img_data[1,:,:,:].copy(), scaling_param=[0] )\n",
    "\n",
    "#####################\n",
    "\n",
    "SO_object, SO_label, out_p =  infer_SOMA3(raw_soma_linear.copy(), NU_labels, default_params) \n",
    "# TODO:  make export ome_tiff export:   XX_object, XX_label, XX_signal\n",
    "#              also fix Path vs. str action for export wrapper\n",
    "# possibly need to do some post-post-processing to make suer that there is only a single SO_Object?\n",
    "\n",
    "\n",
    "chan_name = 'nuclei'\n",
    "out_path = data_path / \"inferred_objects\" \n",
    "object_name = 'SO_object3'\n",
    "\n",
    "SO_object_filen = export_ome_tiff(SO_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)\n",
    "\n",
    "# test: does this export work?\n",
    "object_name = 'SO_label3'\n",
    "SO_label_filen = export_ome_tiff(SO_object, meta_dict, object_name, str(out_path)+\"/\", curr_chan=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ahenrie/Projects/Imaging/mcz_subcell/data/inferred_objects/SO_object3.ome.tiff'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SO_object_filen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ahenrie/Projects/Imaging/mcz_subcell/data/inferred_objects/SO_object3.ome.tiff'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer2.add_image(\n",
    "    raw_soma_linear,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "viewer2.add_image(\n",
    "    SO_object,\n",
    "    scale=scale\n",
    ")\n",
    "viewer2.scale_bar.visible = True\n",
    "\n",
    "viewer2.add_labels(\n",
    "    SO_label,\n",
    "    scale=scale \n",
    ")\n",
    "\n",
    "SO_object_filen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive_window = 200\n",
    "# if adaptive_window % 2 == 0:\n",
    "#     adaptive_window += 1\n",
    "# local_threshold = filters.threshold_sauvola(\n",
    "#     log_image, window_size=adaptive_window\n",
    "# )\n",
    "\n",
    "\n",
    "# # this implimentation doesn't seem to be working despite the fact that I've borrowed from \n",
    "\n",
    "# image_data = log_image\n",
    "# volumetric = True\n",
    " \n",
    "# tolerance=max(np.min(np.diff(np.unique(image_data))) / 2, 0.5 / 65536)\n",
    "# tolerance=np.min(np.diff(np.unique(image_data))) / 2\n",
    "# tolerance = None\n",
    "# #th_method = \"Li\" #skimage.filters.threshold_li,\n",
    "# window_size = 200\n",
    "# th_method=filters.threshold_li\n",
    "    \n",
    "# local_threshold = cp_adaptive_threshold( image_data,\n",
    "#                                                                     th_method, #skimage.filters.threshold_li,\n",
    "#                                                                     volumetric,\n",
    "#                                                                     window_size, \n",
    "#                                                                     tolerance\n",
    "#                                                             )\n",
    "\n",
    "# threshold_correction_factor = 0.9\n",
    "# threshold_global = filters.threshold_li(image_data)\n",
    "# corrected_threshold = local_threshold.copy()*threshold_correction_factor\n",
    "\n",
    "# thresh_min, thresh_max = 0.0000267,.2\n",
    "\n",
    "\n",
    "# # Constrain the local threshold to be within [0.7, 1.5] * global_threshold. It's for the pretty common case\n",
    "# # where you have regions of the image with no cells whatsoever that are as large as whatever window you're\n",
    "# # using. Without a lower bound, you start having crazy threshold s that detect noise blobs. And same for\n",
    "# # very crowded areas where there is zero background in the window. You want the foreground to be all\n",
    "# # detected.\n",
    "# t_min = max(thresh_min, threshold_global * 0.7)\n",
    "# t_max = min(thresh_max, threshold_global * 1.5)\n",
    "\n",
    "# corrected_threshold[corrected_threshold < t_min] = t_min\n",
    "# corrected_threshold[corrected_threshold > t_max] = t_max\n",
    "\n",
    "\n",
    "# bw_adapt = image_data >= corrected_threshold\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
